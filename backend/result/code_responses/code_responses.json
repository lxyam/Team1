{
  "code_question": {
    "question": "你正在开发一个基于协同过滤的推荐系统，需要从MySQL数据库中读取用户行为数据，使用PySpark进行大规模矩阵分解，并将推荐结果存入MongoDB。请用Python编写完整的代码流程，包括数据读取、模型训练和结果存储，并解释关键步骤。",
    "answer": "import pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.recommendation import ALS\nfrom pyspark.sql.functions import col\nimport pymongo\nimport mysql.connector\n\n# 1. 初始化Spark会话\nspark = SparkSession.builder \\\n    .appName(\"RecommendationSystem\") \\\n    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n    .getOrCreate()\n\n# 2. 从MySQL读取数据\nmysql_conn = mysql.connector.connect(\n    host=\"localhost\",\n    user=\"root\",\n    password=\"password\",\n    database=\"user_behavior\"\n)\nquery = \"SELECT user_id, item_id, rating FROM user_ratings\"\nmysql_df = spark.read.format(\"jdbc\") \\\n    .option(\"url\", \"jdbc:mysql://localhost:3306/user_behavior\") \\\n    .option(\"dbtable\", \"(SELECT user_id, item_id, rating FROM user_ratings) as tmp\") \\\n    .option(\"user\", \"root\") \\\n    .option(\"password\", \"password\") \\\n    .load()\n\n# 3. 训练ALS模型\nals = ALS(maxIter=5, regParam=0.01, userCol=\"user_id\", itemCol=\"item_id\", ratingCol=\"rating\")\nmodel = als.fit(mysql_df)\n\n# 4. 为所有用户生成推荐\nuser_recs = model.recommendForAllUsers(10)\n\n# 5. 将结果存入MongoDB\nclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\ndb = client[\"recommendation_db\"]\ncollection = db[\"user_recommendations\"]\n\n# 转换Spark DataFrame为Pandas DataFrame并插入MongoDB\nuser_recs_pd = user_recs.toPandas()\nrecords = user_recs_pd.to_dict('records')\ncollection.insert_many(records)\n\n# 6. 关闭连接\nspark.stop()\nclient.close()\n\n关键步骤说明：\n1. 使用Spark的JDBC连接器从MySQL读取数据\n2. ALS是Spark实现的协同过滤算法，适合大规模矩阵分解\n3. 推荐结果转换为Pandas DataFrame后批量插入MongoDB\n4. 整个过程利用Spark实现分布式计算，适合海量数据场景"
  }
}